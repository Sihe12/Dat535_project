{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import sys\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "# Create a SparkSession with the required packages\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Data_serving_LSTM\") \\\n",
    "    .config(\"spark.executor.extraPythonPackages\", \"spark_tensorflow_distributor,tensorflow\") \\\n",
    "    .config(\"spark.driver.extraPythonPackages\", \"spark_tensorflow_distributor,tensorflow\") \\\n",
    "    .config(\"spark.executorEnv.PYTHONPATH\", \":\".join(sys.path)) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "\n",
    "df = spark.read.parquet(\"hdfs:///project/cleaned_data_parquet\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "total_count = df.count()\n",
    "\n",
    "train_size = int(total_count * 0.6)\n",
    "val_size = int(total_count * 0.2)\n",
    "test_size = int(total_count * 0.2)\n",
    "\n",
    "train_df = df.limit(train_size).orderBy(F.col('date').asc())\n",
    "val_df = df.limit(train_size + val_size).subtract(train_df).orderBy(F.col('date').asc())\n",
    "test_df = df.subtract(train_df).subtract(val_df).orderBy(F.col('date').asc())\n",
    "\n",
    "# Show sizes of the splits\n",
    "print(f\"Train size: {train_df.count()}\")\n",
    "print(f\"Validation size: {val_df.count()}\")\n",
    "print(f\"Test size: {test_df.count()}\")  \n",
    "\n",
    "\n",
    "train_df.show()\n",
    "#Print one row of the dataframe\n",
    "print(train_df.first())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from datetime import datetime\n",
    "\n",
    "def create_sequences(df, input_length=60, output_length=30):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    data = df.collect()\n",
    "\n",
    "    for i in range(len(data) - input_length - output_length + 1):\n",
    "        sequence = [[data[j][1], round(data[j][2], 2), round(data[j][3], 2)] for j in range(i, i + input_length)]\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "        target = [data[i + input_length + j][1] for j in range(output_length)] \n",
    "        targets.append(target)\n",
    "    \n",
    "    return sequences, targets\n",
    "\n",
    "x_train, y_train = create_sequences(train_df)\n",
    "\n",
    "x_val, y_val = create_sequences(val_df)\n",
    "\n",
    "x_test, y_test = create_sequences(test_df)\n",
    "\n",
    "print(x_train[-1])\n",
    "print(y_train[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from spark_tensorflow_distributor import MirroredStrategyRunner\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "from pyspark.accumulators import AccumulatorParam\n",
    "import json\n",
    "\n",
    "class ListAccumulatorParam(AccumulatorParam):\n",
    "    def zero(self, value):\n",
    "        return []\n",
    "\n",
    "    def addInPlace(self, value1, value2):\n",
    "        value1.extend(value2)\n",
    "        return value1\n",
    "\n",
    "class DistributedTrainingCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, accumulator):\n",
    "        super().__init__()\n",
    "        self.accumulator = accumulator\n",
    "            \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        epoch_info = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"loss\": float(logs.get('loss', 0)),\n",
    "            \"val_loss\": float(logs.get('val_loss', 0))\n",
    "        }\n",
    "        self.accumulator.add([epoch_info])\n",
    "\n",
    "# Create accumulator before training\n",
    "training_accumulator = spark.sparkContext.accumulator([], ListAccumulatorParam())\n",
    "\n",
    "def train():\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 200\n",
    "\n",
    "    def make_datasets():\n",
    "        global x_train, y_train, x_val, y_val\n",
    "        \n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(BATCH_SIZE)\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(BATCH_SIZE)\n",
    "        \n",
    "        options = tf.data.Options()\n",
    "        options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "        train_dataset = train_dataset.with_options(options)\n",
    "        val_dataset = val_dataset.with_options(options)\n",
    "        \n",
    "        return train_dataset, val_dataset\n",
    "\n",
    "    def make_test_dataset():\n",
    "        global x_test, y_test\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)\n",
    "        return test_dataset\n",
    "\n",
    "    # https://medium.com/@sebastienwebdev/forecasting-weather-patterns-with-lstm-a-python-guide-without-dates-433f0356136c\n",
    "    def build_and_compile_lstm_model():\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.LSTM(50, return_sequences=True, input_shape=(60, 3)),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.LSTM(50),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(30)\n",
    "        ])\n",
    "        model.compile(\n",
    "            loss=\"mean_squared_error\",\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            metrics=[\"mae\", \"mse\"]\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    # Load datasets\n",
    "    train_datasets, val_datasets = make_datasets()\n",
    "    test_datasets = make_test_dataset()\n",
    "\n",
    "    # Build model\n",
    "    model = build_and_compile_lstm_model()\n",
    "    \n",
    "    # Early stopping callback to prevent overfitting\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=50,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    distributed_callback = DistributedTrainingCallback(training_accumulator)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(\n",
    "        x=train_datasets, \n",
    "        epochs=EPOCHS, \n",
    "        verbose=1,\n",
    "        validation_data=val_datasets,\n",
    "        callbacks=[early_stopping_cb, distributed_callback]\n",
    "    )\n",
    "\n",
    "    # Evaluate and calculate metrics\n",
    "    results= model.evaluate(test_datasets, return_dict=True)\n",
    "    y_pred = model.predict(test_datasets)\n",
    "    \n",
    "    return {\n",
    "        \"MAE\": float(results[\"mae\"]),\n",
    "        \"MSE\": float(results[\"mse\"]),\n",
    "        \"RMSE\": np.sqrt(results[\"mse\"]),\n",
    "        \"y_pred\": y_pred\n",
    "    }\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run distributed training\n",
    "runner = MirroredStrategyRunner(num_slots=3, use_gpu=False)\n",
    "metrics_results = runner.run(train)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "training_info = training_accumulator.value\n",
    "print(f\"Training info: {training_info}\")\n",
    "\n",
    "print(\"\\nMetrics Results:\")\n",
    "print(\"MAE: \", metrics_results[\"MAE\"])\n",
    "print(\"MSE: \", metrics_results[\"MSE\"])\n",
    "print(\"RMSE: \", metrics_results[\"RMSE\"])\n",
    "\n",
    "y_pred = np.array(metrics_results[\"y_pred\"])\n",
    "true_values = test_df.select(\"temperature\").collect()\n",
    "true_values = true_values[60:]\n",
    "dates = test_df.select(\"date\").collect()\n",
    "dates = dates[60:]\n",
    "dates = [datetime.strptime(date[0], '%Y-%m-%d') for date in dates]\n",
    "\n",
    "predictions = {}\n",
    "y_pred_mean = []\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if dates[i+j] not in predictions:\n",
    "            predictions[dates[i+j]] = []\n",
    "        predictions[dates[i+j]].append(y_pred[i][j])\n",
    "\n",
    "all_pred_dates = []\n",
    "all_predictions = []\n",
    "count_correct = 0\n",
    "count_total = 0\n",
    "\n",
    "count = 0\n",
    "for date, preds in predictions.items():\n",
    "    y_pred_mean.append(np.mean(preds))\n",
    "    \n",
    "    true_value = true_values[count][0]\n",
    "    for pred in preds:\n",
    "        all_pred_dates.append(date)\n",
    "        all_predictions.append(pred)\n",
    "        \n",
    "        if abs(true_value - pred) <= 1:\n",
    "            count_correct += 1\n",
    "        count_total += 1\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "accuracy = count_correct / count_total\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12), sharex=True)\n",
    "\n",
    "ax1.plot(dates, [tv[0] for tv in true_values], \n",
    "         label=\"Actual\", \n",
    "         color=\"blue\", \n",
    "         linewidth=1.5)\n",
    "ax1.plot(dates, y_pred_mean, \n",
    "         color=\"red\", \n",
    "         label=\"Mean Predictions\", \n",
    "         linewidth=1.5)\n",
    "\n",
    "ax1.set_ylabel(\"Temperature\", fontsize=12)\n",
    "ax1.set_title(\"Temperature Over Time: Actual vs Mean Predictions\", \n",
    "              fontsize=14, \n",
    "              pad=10)\n",
    "\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(dates, [tv[0] for tv in true_values], \n",
    "         label=\"Actual\", \n",
    "         color=\"blue\", \n",
    "         linewidth=1.5)\n",
    "ax2.scatter(all_pred_dates, all_predictions, \n",
    "           color=\"red\", \n",
    "           alpha=1, \n",
    "           s=20, \n",
    "           label=\"Individual Predictions\")\n",
    "\n",
    "ax2.set_xlabel(\"Date\", fontsize=12)\n",
    "ax2.set_ylabel(\"Temperature\", fontsize=12)\n",
    "ax2.set_title(\"Temperature Over Time: Actual vs Individual Predictions\", \n",
    "              fontsize=14, \n",
    "              pad=10)\n",
    "\n",
    "ax2.legend()\n",
    "\n",
    "plt.xticks(ticks=dates[::90], \n",
    "           labels=[date.strftime('%Y-%m-%d') for date in dates[::90]], \n",
    "           rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
